{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, Conv2D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  image                mask\n",
      "0      10452_sat_08.jpg   10452_mask_08.jpg\n",
      "1      10452_sat_18.jpg   10452_mask_18.jpg\n",
      "2     111335_sat_00.jpg  111335_mask_00.jpg\n",
      "3     111335_sat_01.jpg  111335_mask_01.jpg\n",
      "4     111335_sat_02.jpg  111335_mask_02.jpg\n",
      "...                 ...                 ...\n",
      "5103  998002_sat_31.jpg  998002_mask_31.jpg\n",
      "5104  998002_sat_32.jpg  998002_mask_32.jpg\n",
      "5105  998002_sat_40.jpg  998002_mask_40.jpg\n",
      "5106  998002_sat_41.jpg  998002_mask_41.jpg\n",
      "5107  998002_sat_50.jpg  998002_mask_50.jpg\n",
      "\n",
      "[5108 rows x 2 columns]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "label=pd.read_csv('Forest Segmented\\meta_data.csv')\n",
    "\n",
    "classes = {\n",
    "    '0': (0, 0, 0,),\n",
    "    '1': (255, 255, 255)\n",
    "}\n",
    "\n",
    "print(label)\n",
    "\n",
    "path_original_images = 'Forest Segmented/images'\n",
    "path_label_images = 'Forest Segmented/masks'\n",
    "num_class = 2\n",
    "\n",
    "print(num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(arr1, arr2):\n",
    "    randomize = np.arange(len(arr1))\n",
    "    np.random.shuffle(randomize)\n",
    "    return arr1[randomize], arr2[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['848728_sat_52.jpg' '122104_sat_22.jpg' '830444_sat_45.jpg' ...\n",
      " '277994_sat_53.jpg' '352808_sat_04.jpg' '810368_sat_64.jpg']\n",
      "['848728_mask_52.jpg' '122104_mask_22.jpg' '830444_mask_45.jpg' ...\n",
      " '277994_mask_53.jpg' '352808_mask_04.jpg' '810368_mask_64.jpg']\n"
     ]
    }
   ],
   "source": [
    "img, msk = label.items()\n",
    "image, mask = shuffle(np.array(img[1]), np.array(msk[1]))\n",
    "print(image)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5108\n",
      "5108\n"
     ]
    }
   ],
   "source": [
    "print(image.shape[0])\n",
    "print(mask.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_images():\n",
    "    temp_img = []\n",
    "    for a in range(image.shape[0]):\n",
    "        temp_img.append(tf.keras.preprocessing.image.img_to_array(tf.keras.utils.load_img(f\"{path_original_images}/{image[a]}\", target_size=(128,128))))\n",
    "    \n",
    "    return np.array(temp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mod_images(mod_path):\n",
    "    temp_img = []\n",
    "    for a in range(image.shape[0]):\n",
    "        temp_img.append(tf.keras.preprocessing.image.img_to_array(tf.keras.utils.load_img(f\"{mod_path}/{image[a]}\", target_size=(128,128))))\n",
    "    \n",
    "    return np.array(temp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classconvert():\n",
    "    rtn = []\n",
    "    for a in range(mask.shape[0]):\n",
    "        img_mask = tf.keras.preprocessing.image.img_to_array(tf.keras.utils.load_img(f\"{path_label_images}/{mask[a]}\", target_size=(128,128)))\n",
    "        temp_mask = np.zeros(shape=(img_mask.shape[0], img_mask.shape[1]), dtype = np.uint32)\n",
    "\n",
    "        for row in range(img_mask.shape[0]):\n",
    "            for col in range(img_mask.shape[1]):\n",
    "                if img_mask[row, col, 0] > 128:\n",
    "                    temp_mask[row, col] = 1\n",
    "        temp_mask = np.reshape(temp_mask, (temp_mask.shape[0], temp_mask.shape[1], 1))\n",
    "        rtn.append(temp_mask)\n",
    "    return np.array(rtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n",
      "(5108, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "x = get_original_images()\n",
    "y = classconvert()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "np.save('x.npy',x)\n",
    "np.save('y.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "noise = get_mod_images('mod_datasets/gnoise')\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "edge = get_mod_images('mod_datasets/edge')\n",
    "print(edge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "hist = get_mod_images('mod_datasets/histo')\n",
    "print(hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "edge_noise = get_mod_images('mod_datasets/edge_gnoise')\n",
    "print(edge_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "edge_hist = get_mod_images('mod_datasets/edge_histo')\n",
    "print(edge_hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "hist_noise = get_mod_images('mod_datasets/gnoise_histo')\n",
    "print(hist_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5108, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "all = get_mod_images('mod_datasets/all')\n",
    "print(all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"noise.npy\", noise)\n",
    "np.save(\"edge.npy\", edge)\n",
    "np.save(\"hist.npy\", hist)\n",
    "np.save(\"edge_noise.npy\", edge_noise)\n",
    "np.save(\"edge_hist.npy\", edge_hist)\n",
    "np.save(\"hist_noise.npy\", hist_noise)\n",
    "np.save(\"all.npy\", all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.load(\"noise.npy\",)\n",
    "edge = np.load(\"edge.npy\")\n",
    "hist = np.load(\"hist.npy\")\n",
    "edge_noise = np.load(\"edge_noise.npy\")\n",
    "edge_hist = np.load(\"edge_hist.npy\")\n",
    "hist_noise = np.load(\"hist_noise.npy\")\n",
    "all  = np.load(\"all.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_indexes = random.sample(range(len(noise)), int(len(noise) * 0.2))\n",
    "print(len(random_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_dataset(dataset, noiseset, noiselevel = 0.5):\n",
    "    temp = []\n",
    "    random_indexes = random.sample(range(len(dataset)), int(len(dataset) * noiselevel))\n",
    "    for i in range(len(dataset)):\n",
    "        if i in random_indexes:\n",
    "            temp.append(noiseset[i])\n",
    "        else:\n",
    "            temp.append(dataset[i])\n",
    "    return np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4086, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "original_dataset = get_original_images()\n",
    "dataset_noise = generate_dataset(original_dataset[0:4086], noise[0:4086])\n",
    "\n",
    "\n",
    "dataset_edge_noise = generate_dataset(edge[0:4086], edge_noise[0:4086])\n",
    "\n",
    "dataset_hist_noise = generate_dataset(hist[0:4086], hist_noise[0:4086])\n",
    "dataset_all = generate_dataset(edge_hist[0:4086], all[0:4086])\n",
    "print(dataset_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"dataset_noise.npy\", dataset_noise)\n",
    "np.save(\"dataset_edge_noise.npy\", dataset_edge_noise)\n",
    "np.save(\"dataset_hist_noise.npy\", dataset_hist_noise)\n",
    "np.save(\"dataset_all.npy\", dataset_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
